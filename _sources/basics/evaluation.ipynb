{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(evaluation)=\n",
    "# Evaluation\n",
    "\n",
    "\n",
    "\n",
    "Measuring the results of a source separation approach is a challenging problem.\n",
    "Generally, there are two main categories for evaluating the outputs of a source\n",
    "separation approach: objective and subjective. Objective measures rate\n",
    "separation quality by performing a set of calculations that compare the output \n",
    "signals of a separation system to the ground truth isolated sources. Subjective\n",
    "measures involve having human raters give scores for the source separation\n",
    "system's output.\n",
    "\n",
    "Objective and subjective measures both have benefits and drawbacks. Objective\n",
    "measures struggle because there are many aspects of human perception that are\n",
    "extremely difficult capture by computational means alone. However, compared to\n",
    "subjective measures, they are much faster and cheaper to obtain. On the other\n",
    "hand, subjective measures are expensive, time-consuming, and subject to the\n",
    "variability of human raters, but they can be more reliable than objective\n",
    "measures because actual human listeners are involved in the evaluation process.\n",
    "\n",
    "\n",
    "Objective measures are, by far, much more popular than subjective measures, but\n",
    "we feel it is worth understanding them both to some extent.\n",
    " \n",
    "\n",
    "\n",
    "## Objective Measures\n",
    "\n",
    "\n",
    "### SDR, SIR, and SAR\n",
    "\n",
    "Source-to-Distortion Ratio (SDR), Source-to-Interference Ratio (SIR), and\n",
    "Source-to-Artifact Ratio (SAR) are, to date, the most widely used methods\n",
    "for evaluating a source separation system's output. \n",
    "\n",
    "An estimate of a Source $\\hat{s}_i$ is assumed to actually be composed\n",
    "of four separate components,\n",
    "\n",
    "$$\n",
    "\\hat{s}_i = s_{\\text{target}} + e_{\\text{interf}} + e_{\\text{noise}} + e_{\\text{artif}},\n",
    "$$\n",
    "\n",
    "where $s_{\\text{target}}$ is the true source, and $e_{\\text{interf}}$, $e_{\\text{noise}}$, and\n",
    "$e_{\\text{artif}}$ are error terms for interference, noise, and added \\text{artif}acts,\n",
    "respectively. The actual calculations of these terms is quite complex, so\n",
    "we refer the curious reader to the original paper for their exact calculation:\n",
    "{cite}`vincent2006performance`.\n",
    "\n",
    "Using these four terms, we can define our measures. All of the measures\n",
    "are in terms of decibels (dB), with higher values being better.\n",
    "To calculate they require access to the ground truth isolated sources and\n",
    "are usually calculated on a signal that has been divided into short\n",
    "windows of a few seconds long. \n",
    "\n",
    "\n",
    "**Source-to-Artifact Ratio (SAR)**\n",
    "\n",
    "$$\n",
    "\\text{SAR} := 10 \\log_{10} \\left( \\frac{\\| s_{\\text{target}} + e_{\\text{interf}} + e_{\\text{noise}} \\|^2}{ \\| e_{\\text{artif}} \\|^2} \\right)\n",
    "$$\n",
    "\n",
    "This is usually interpreted as the amount of unwanted artifacts a source \n",
    "estimate has with relation to the true source.\n",
    "\n",
    "\n",
    "**Source-to-Interference Ratio (SIR)**\n",
    "\n",
    "$$\n",
    "\\text{SIR} := 10 \\log_{10} \\left( \\frac{\\| s_{\\text{target}} \\|^2}{ \\| e_{\\text{interf}} \\|^2} \\right)\n",
    "$$\n",
    "\n",
    "This is usually interpreted as the amount of other sources that can be\n",
    "heard in a source estimate. This is most close to the concept of\n",
    "[\"bleed\", or \"leakage\"](https://en.wikipedia.org/wiki/Spill_(audio)). \n",
    "\n",
    "\n",
    "**Source-to-Distortion Ratio (SDR)**\n",
    "\n",
    "$$\n",
    "\\text{SDR} := 10 \\log_{10} \\left( \\frac{\\| s_{\\text{target}} \\|^2}{ \\| e_{\\text{interf}} + e_{\\text{noise}} + e_{\\text{artif}} \\|^2} \\right)\n",
    "$$\n",
    "\n",
    "SDR is usually considered to be an overall measure of how good a source\n",
    "sounds. If a paper only reports one number for estimated quality, it\n",
    "is usually SDR.\n",
    "\n",
    "\n",
    "```{note}\n",
    "As of this writing (October 2020), the best reported SDR for singing\n",
    "voice separation on MUSDB18 is $7.24 dB$. {cite}`takahashi2020d3net`\n",
    "Recent research papers have been reporting vocal SDRs on MUSDB18\n",
    "in the range of 6-7 dB.\n",
    "Compare the SDR of different systems at this\n",
    "[Papers with Code link.](https://paperswithcode.com/sota/music-source-separation-on-musdb18)\n",
    "```\n",
    "\n",
    "\n",
    "**Signal-to-Noise Ratio (SNR)**\n",
    "\n",
    "This is not used as widely, but does appear sometimes in source separation:\n",
    "\n",
    "$$\n",
    "\\text{SNR} := 10 \\log_{10} \\left( \\frac{\\| s_{\\text{target}} \\|^2}{ \\| s_{\\text{target}} - \\hat{s} \\|^2} \\right)\n",
    "$$\n",
    "\n",
    "where $\\hat{s}$ is the estimate of $s_{\\text{target}}$.\n",
    "\n",
    "\n",
    "\n",
    "#### SI-SDR\n",
    "\n",
    "```{figure} ../images/basics/sdr_vs_sisdr.png\n",
    "---\n",
    "alt: Waveform shown at many different time scales from a few seconds to a few samples.\n",
    "name: sdr_vs_sisdr\n",
    "---\n",
    "The way SDR calculates the $e_{\\text{interf}}$, $e_{\\text{noise}}$, and\n",
    "$e_{\\text{artif}}$ terms\n",
    "can lead to issues where the original signal (top) can be horribly degraded (bottom) \n",
    "and still get a very high SDR score.\n",
    "Image used courtesy of Jonathan Le Roux. {cite}`le2019sdr`\n",
    "```\n",
    "\n",
    "\n",
    "A handful of issues have been brought up in the years since it was\n",
    "originally proposed. Although some of the issues are implementation-specific,\n",
    "one issue that persists is that SDR is easy to \"cheat\" on. The way\n",
    "that SDR calculates the $e_{\\text{interf}}$, $e_{\\text{noise}}$, and\n",
    "$e_{\\text{artif}}$ terms can cause issues where scores are artificially\n",
    "inflated.\n",
    "\n",
    "Scale-Invariant Source-to-Distortion Ratio (SI-SDR) aims to remedy this\n",
    "by removing SDR's dependency on the amplitude scaling of the signal.\n",
    "{cite}`le2019sdr` It also comes with accompanying SI-SAR, and SI-SIR,\n",
    "which corresponds to SAR and SIR described above, respectively.\n",
    "Although these measures are not sensitive to amplitude scaling, it\n",
    "is a quicker computation because it does not require windowing\n",
    "the estimated and ground truth signals like SDR.\n",
    "\n",
    "In {numref}`sdr_vs_sisdr`, the discrepancy between SDR and SI-SDR\n",
    "scores is shown. The top spectrogram shows the ground truth signal.\n",
    "Above it are its scores for SDR, SNR, and SI-SDR. As expected the\n",
    "ground truth signal gets high values for SDR, SNR, and SI-SDR\n",
    "(268.1 dB, infinity dB, and infinity dB, respectively. Shown above the plot).\n",
    "The bottom spectrogram shows a highly degraded version of the top\n",
    "signal. While the SI-SDR, and SNR are quite low (-4.72 dB and 1.26 dB,\n",
    "respectively), the SDR value is still quite high (11.56 db). For\n",
    "reference, this is a speech signal and this SDR value is higher than\n",
    "state-of-the-art speech separation systems from a few years ago.\n",
    "\n",
    "#### Reported SDRs\n",
    "\n",
    "Many times SDRs are reported in research papers. When this happens, it\n",
    "is common to show just one number for SDR, but usually this number\n",
    "represents the mean of a distribution of SDRs calculated on a dataset.\n",
    "This is not the best practice, unfortunately, and the authors of this\n",
    "tutorial are certainly guilty of it. But when reading papers, be aware\n",
    "that this number is a summary statistic that could obscure a whole\n",
    "distribution.\n",
    "\n",
    "\n",
    "#### Does Higher SDR Imply Better Quality?\n",
    "\n",
    "\n",
    "SDR doesn't tell you the whole story. Consider the following four audio examples.\n",
    "First is the input mixture, then the ground truth reference source,\n",
    "followed by two outputs from two different source separation \n",
    "models named ConvTasnet and Open-Unmix, respectively. Have a listen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install nussl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "import nussl\n",
    "mix = nussl.AudioSignal(nussl.efz_utils.download_audio_file('zeno_sign_mix_LerFJoZ.wav', verbose=False))\n",
    "ref = nussl.AudioSignal(nussl.efz_utils.download_audio_file('zeno_sign_vocals-reference.wav', verbose=False))\n",
    "convtasnet = nussl.AudioSignal(nussl.efz_utils.download_audio_file('zeno_sign_vocals-convtasnet.wav', verbose=False))\n",
    "open_unmix = nussl.AudioSignal(nussl.efz_utils.download_audio_file('zeno_sign_vocals-openunmix.wav', verbose=False))\n",
    "\n",
    "print('Mixture')\n",
    "mix.embed_audio()\n",
    "\n",
    "print('Reference Source')\n",
    "ref.embed_audio()\n",
    "\n",
    "print('ConvTasnet Source')\n",
    "convtasnet.embed_audio()\n",
    "\n",
    "print('Open-Unmix Estimate')\n",
    "_ = open_unmix.embed_audio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To our ears, the ConvTasnet output sounds much worse than the Open-Unmix output,\n",
    "but these two estimates both have the same SDR!\n",
    "\n",
    "This is all to say that while SDR can give you a rough\n",
    "idea of how good an estimate might sound, it does not capture\n",
    "everything. Listen to your outputs!\n",
    "\n",
    "(The original input mix and reference are from MUSDB18 and the separation examples kindly provided by Fabian-Robert Stöter.)\n",
    "\n",
    "## Subjective Measures\n",
    "\n",
    "Having a human or set of humans evaluate a separation result is the gold standard\n",
    "for measuring the quality of a system. However, this is rarely done due to how\n",
    "difficult it is to get reliable evaluation data.\n",
    "\n",
    "In a perfect world we would have a handful of well-trained audio\n",
    "engineers rate an algorithm's output in a sound treated room. That's\n",
    "exactly the formula for the [MUSHRA](https://en.wikipedia.org/wiki/MUSHRA)\n",
    "tests, which rarely—if ever—happen when evaluating source separation\n",
    "because of how time-consuming and expensive they are.\n",
    "\n",
    "Some studies have come have shown that crowd sourcing results from\n",
    "MUSHRA-like online listening studies can be an effective alternative\n",
    "to trained experts in a controlled setting. {cite}`cartwright2016fast,schoeffler2018webmushra`\n",
    "Although this is much\n",
    "cheaper than a full-blown MUSHRA study, it still costs money (\\$100-200 USD)\n",
    "and takes a few days to get the results. Calculating SDR values on\n",
    "the other hand is virtually free and takes a few hours at most."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
