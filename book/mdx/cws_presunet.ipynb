{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ed227f",
   "metadata": {},
   "source": [
    "# Channel-wise Subband Phase-aware ResUNet\n",
    "\n",
    "Channel-wise Subband Phase-aware ResUNet (**CWS-PResUNet**) is the model we submitted for the 2021 ISMIR MDX Challenge. On the MUSDB18HQ dataset, our proposed CWS-PResUNet achieves high performance on vocals separation with an 8.92 SDR score. And our final submitted system ByteMSS ranks the 2nd on vocals score and 5th on average scores in the 2021 ISMIR MDX Challenge (leaderboard A).\n",
    "\n",
    "## Materials\n",
    "\n",
    "- To reproduce our work: [link to github](https://github.com/haoheliu/2021-ISMIR-MSS-Challenge-CWS-PResUNet)\n",
    "- Use pretrained models online: [colab](https://colab.research.google.com/drive/1E2yJLWN8MH6GJUw15cj490E2BaeAcGie?usp=sharing)\n",
    "- To perform subband operations: [link to github](https://github.com/haoheliu/torchsubband)\n",
    "\n",
    "## Architecture overview\n",
    "\n",
    "![figure_cws_presunet](../images/cws_presunet/diagram_cws_presunet.png)\n",
    "\n",
    "Our system is a source-dedicated models to perform music source separation (MSS). The overall pipline of our CWS-PResUNet is shown in the above image. The two major differences in this models include 1) Working on subband feature domain, 2) Estimating subband unbounded mask and subband phase variations.\n",
    "\n",
    "Details of our model can be found in [our paper](https://s3.eu-west-1.amazonaws.com/production-main-contentbucket52d4b12c-1x4mwd6yn8qjn/0e755236-5bb2-4ef0-af65-ac06452d2b60.pdf).\n",
    "\n",
    "\n",
    "## Subband feature for MSS\n",
    "\n",
    "In my opinion, subband features can inspire more innovative ideas in MSS as an alternative to the widely used spectrogram or time domain feature. That's because:\n",
    "\n",
    "1. Subband decomposition is revertable. (Just like STFT/iSTFT)\n",
    "2. Subband feature decouple information in different subbands.\n",
    "3. Subband feature lower the data dimension (e.g. 44.1kHz -> 11.025kHz). \n",
    "\n",
    "In our model, we do not directly use waveform or spectrogram as input feature. Instead, we perform time domain subband decomposition (analysis) first and then perform separation task on their spectrograms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027a6d9c",
   "metadata": {},
   "source": [
    "## Experiment results\n",
    "\n",
    "Our final submitted system use CWS-PResUNet to separate *vocals* and *other*. For *bass* and *drums*, we directly use the baseline demucs because it performs better. \n",
    "\n",
    "|    Models    | Vocals | Drums |  Bass | Other | Average |\n",
    "|:------------:|:------:|:-----:|:-----:|:-----:|:-------:|\n",
    "|     X-UMX    |  6.61  |  6.47  | 5.43  | 4.64  |  5.79  |\n",
    "|     D3Net    |  7.24  |  7.01 |  5.25 |  4.53 |  6.01   |\n",
    "|    Demucs    |  6.89  | **6.57**  | **6.53**  | 5.14  |  6.28   |\n",
    "| CWS-PResUNet |  **8.92**  | 6.38  | 5.93  | **5.84**  |  6.77   |\n",
    "|    ByteMSS   |  8.92  | 6.57  | 6.53  | 5.84  |  **6.97**   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec332a2b",
   "metadata": {},
   "source": [
    "\n",
    "## Contacts\n",
    "\n",
    "- Email: haoheliu@gmail.com\n",
    "- Github@haoheliu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97416eac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
